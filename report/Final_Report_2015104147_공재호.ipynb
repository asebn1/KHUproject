{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경희대학교 컴퓨터공학과 공지사항 및 취업정보 분석(2015104147 공재호)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 주제 선정 이유<br>\n",
    " 텀 프로젝트 주제는 경희대학교 컴퓨터공학과 공지사항 및 취업 정보 분석이다. 경희대학교 학부 학생들은 학교의 공지사항 및 취업 정보를 알고 싶다. 공지사항이 경희톡으로 오기도 하지만 보편화한 지 얼마 되지 않았다. 또한, 알고 싶은 정보가 오지 않을 때도 많기 때문에 직접 찾아보아야 한다. 내가 궁금한 기업의 취업 정보가 언제 전달될지와 공지사항에서는 내가 궁금한 공지사항이 언제 공지될지 예상할 수 있도록 한다. 이전 2015년부터 현재까지의 공지사항 및 취업 정보를 바탕으로 정보를 분석하여 언제 공지되는지 예상할 수 있다.<br>\n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.가설 정의<br>\n",
    " 2015년부터 2019년까지 매년 9월마다 가을 프로그래밍 경시대회가 공지된다고 가정하자. 그렇다면, 2020년 9월에도 가을 프로그래밍 경시대회가 공지된다는 것을 유추할 수 있다. 이처럼 주기적으로 공지되는 타이틀 정보를 저장하여 분석한다. 분석된 자료를 통해 앞으로 공지될 공지사항 및 취업 정보를 예측할 수 있다.<br>\n",
    " <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.인터넷을 통한 데이터 획득<br>\n",
    "1. 경희대학교 SW융합대학 - 컴퓨터공학과 - 공지사항<br>\n",
    " 공지사항은 등록일을 기준으로 하며 번호와 공지 제목이 있다. 등록일과 공지 제목을 통해 달마다 어떤 내용이 공지되는지 분석하여 확인할 수 있다.<br>\n",
    "2. 경희대학교 SW융합대학 - 컴퓨터공학과 - 취업<br>\n",
    " 취업 정보는 등록일을 기준으로 하며 번호와 제목이 있다. 등록일과 제목을 통해 달마다 어떤 기업의 취업 정보가 공지되는지 분석하여 확인할 수 있다.<br>\n",
    " <br>\n",
    " \n",
    " 파이썬 크롤링을 통해 정보를 csv 파일 형식으로 저장한다. 이후 csv파일을 토대로 내용을 분석한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.분석을 위한 데이터의 가공<br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<데이터를 수집하고 분석하기 위한 사전 작업><br>\n",
    "\n",
    " 1. beautifulSoup4를 설치 (pip install beautifulSoup4)\n",
    " 2. url을 통해 file을 open하기 위한 urllib 설치 (pip install urllib)\n",
    " 3. 크롤링 데이터를 csv 파일로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 공지사항의 정보들을 추출한다. 번호, 제목, 등록일자를 추출한다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▲ 페이지를 count하여 페이지 끝까지 정보 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▲ 공지사항 정보 추출 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def getNotice():\n",
    "    #총 페이지\n",
    "    count = 42\n",
    "\n",
    "    #홍페이지 주소. 페이지 마다 count 해주어 게시판 글 모두 긁어옴\n",
    "    baseurl = 'http://ce.khu.ac.kr/index.php?pg=' + str(count) + '&page=list&hCode=BOARD&bo_idx=2&sfl=&stx='\n",
    "    res = req.urlopen(baseurl)\n",
    "    soup = BeautifulSoup(res, 'html.parser')\n",
    "    \n",
    "    # 호환되도록 버퍼 -1과 utf8 적용\n",
    "    f = open('Notice.csv', 'a', -1, \"utf-8\")\n",
    "\n",
    "    #페이지가 끝날때까지 반복\n",
    "    while(1):\n",
    "        baseurl = 'http://ce.khu.ac.kr/index.php?pg=' + str(count) + '&page=list&hCode=BOARD&bo_idx=2&sfl=&stx='\n",
    "        res = req.urlopen(baseurl)\n",
    "        soup = BeautifulSoup(res, 'html.parser')\n",
    "\n",
    "        if count == 42:\n",
    "\n",
    "            #마지막 페이지일 때 게시글 수가 20개가 아니므로\n",
    "            for i in range(12, 1, -1):\n",
    "                #번호 삽입\n",
    "                temp1 = '#board_list >tbody > tr:nth-child(' + str(i) + ') > td:nth-child(1)'\n",
    "                noticeNum = soup.select(temp1)[0].text\n",
    "                #제목 삽입\n",
    "                temp2 = '#board_list > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(2) > a'\n",
    "                noticeText = soup.select(temp2)[0].text\n",
    "                #등록일 삽입\n",
    "                temp3 = '#board_list > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(5)'\n",
    "                noticeym = soup.select(temp3)[0].text\n",
    "                print(noticeNum + ',' + noticeText  + ',' + noticeym)\n",
    "                f.write(noticeNum + ',' + noticeText  + ',' + noticeym + '\\n')\n",
    "       \n",
    "        else :\n",
    "            #기본 페이지와 같은 수일때 적용\n",
    "            for i in range(21, 1, -1):\n",
    "                #번호 삽입\n",
    "                temp1 = '#board_list >tbody > tr:nth-child(' + str(i) + ') > td:nth-child(1)'\n",
    "                noticeNum = soup.select(temp1)[0].text\n",
    "                #제목 삽입\n",
    "                temp2 = '#board_list > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(2) > a'\n",
    "                noticeText = soup.select(temp2)[0].text\n",
    "                noticeText = noticeText.replace(',','')\n",
    "                \n",
    "                #등록일 삽입\n",
    "                temp3 = '#board_list > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(5)'\n",
    "                noticeym = soup.select(temp3)[0].text\n",
    "                print(noticeNum + ',' + noticeText  + ',' + noticeym)\n",
    "                f.write(noticeNum + ',' + noticeText  + ',' + noticeym + '\\n')\n",
    "        count -= 1\n",
    "\n",
    "        #게시물 끝 도달시 종료\n",
    "        if count == 0:\n",
    "            break\n",
    "\n",
    "![](../image/source1.jpg) <br>\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 취업정보란의 정보들을 추출한다. 번호, 제목, 등록일자를 추출한다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▲ 페이지를 count하여 페이지 끝까지 정보 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▲ 취업정보란의 정보 추출 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#홈페이지에서 크롤링으로 값 받아오기\n",
    "def getEmployment():\n",
    "\n",
    "    #총 페이지\n",
    "    count = 17\n",
    "\n",
    "    #홍페이지 주소. 페이지 마다 count 해주어 게시판 글 모두 긁어옴\n",
    "    baseurl = 'http://ce.khu.ac.kr/index.php?pg=' + str(count) + '&page=list&hCode=BOARD&bo_idx=3&sfl=&stx='\n",
    "    res = req.urlopen(baseurl)\n",
    "    soup = BeautifulSoup(res, 'html.parser')\n",
    "    \n",
    "    # 호환되도록 버퍼 -1과 utf8 적용\n",
    "    f = open('Employment.csv', 'a', -1, \"utf-8\")\n",
    "    \n",
    "    #페이지가 끝날때까지 반복\n",
    "    while(1):\n",
    "        baseurl = 'http://ce.khu.ac.kr/index.php?pg=' + str(count) + '&page=list&hCode=BOARD&bo_idx=3&sfl=&stx='\n",
    "        res = req.urlopen(baseurl)\n",
    "        soup = BeautifulSoup(res, 'html.parser')\n",
    "        \n",
    "        #마지막 페이지일 때 게시글 수가 20개가 아니므로\n",
    "        if count == 17:\n",
    "            for i in range(19, 0, -1):\n",
    "                #번호 삽입\n",
    "                temp1 = '#board_list >tbody > tr:nth-child(' + str(i) + ') > td:nth-child(1)'\n",
    "                noticeNum = soup.select(temp1)[0].text\n",
    "                #제목 삽입\n",
    "                temp2 = '#board_list > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(2) > a'\n",
    "                noticeText = soup.select(temp2)[0].text\n",
    "                #등록일 삽입\n",
    "                temp3 = '#board_list > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(5)'\n",
    "                noticeym = soup.select(temp3)[0].text\n",
    "                print(noticeNum + ',' + noticeText  + ',' + noticeym)\n",
    "                f.write(noticeNum + ',' + noticeText  + ',' + noticeym + '\\n')\n",
    "   \n",
    "        else :\n",
    "            #기본 페이지와 같은 수일때 적용\n",
    "            for i in range(20, 0, -1):\n",
    "                #번호 삽입\n",
    "                temp1 = '#board_list >tbody > tr:nth-child(' + str(i) + ') > td:nth-child(1)'\n",
    "                noticeNum = soup.select(temp1)[0].text\n",
    "                #제목 삽입\n",
    "                temp2 = '#board_list > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(2) > a'\n",
    "                noticeText = soup.select(temp2)[0].text\n",
    "                noticeText = noticeText.replace(',','')\n",
    "                \n",
    "                #등록일 삽입\n",
    "                temp3 = '#board_list > tbody > tr:nth-child(' + str(i) + ') > td:nth-child(5)'\n",
    "                noticeym = soup.select(temp3)[0].text\n",
    "                print(noticeNum + ',' + noticeText  + ',' + noticeym)\n",
    "                f.write(noticeNum + ',' + noticeText  + ',' + noticeym + '\\n')\n",
    "        count -= 1\n",
    "       \n",
    "        #게시물 끝 도달시 종료\n",
    "        if count == 0:\n",
    "            break\n",
    "            \n",
    "\n",
    "![](../image/source2.jpg) <br>            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 크롤링을 통해 저장된 csv의 정보를 활용하여 앞으로 나올 공지사항과 취업정보를 예상한다.\n",
    "예시)<br>\n",
    "1-1) 2016년부터 2019년까지 매년 9월 혹은 10월에 KHU 가을 프로그래밍 경시대회 안내가 나오는 것을 확인한다.<br>\n",
    "1-2) 2020년에도 9월 혹은 10월에 KHU 가을 프로그래밍 경시대회가 나올 수 있음을 예상할 수 있다.<br>\n",
    "\n",
    "2-1) 2015년부터 2019년까지 매년 4월 삼성 취업설명회 안내가 나오는 것을 취업정보란을 통해 확인한다.<br>\n",
    "2-2) 2020년에도 4월에 삼성 취업설명회 안내가 나올 수 있음을 예상할 수 있다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 앞선 과정을 통해 얻은 데이터를 이용하여 앞으로 나올 공지사항 혹은 취업 정보를 예상한다.\n",
    "[3]의 과정을 통해 경희대학교 컴퓨터공학과와 취업정보란을 통해 앞으로 나올 정보를 예상할 수 있다.<br>\n",
    "구한 csv 파일의 [제목]란을 통해 알아보고자 하는 정보를 string형식으로 입력해 정보를 찾는다. <br>\n",
    "<br>\n",
    "또한, 검색된 결과에서 등록일을 확인한다. 등록일 사이에 얼만큼의 주기를 가지고 규칙이 있는지 확인한다.<br>\n",
    "만약 규칙이 있다면, 다음 2020년 이후에도 같은 주기로 비슷한 내용의 공지가 올라올 수 있음을 예상한다. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 분석 결과 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "컴퓨터공학과의 공지사항이 시작된 2015-06-30 부터 2020-05-30까지를 기준으로 공지사항 내용이 수집되었다. <br>\n",
    "컴퓨터공학과 취업정보란 시작된 2015-06-30 부터 2020-05-30까지를 기준으로 취업정보가 수집되었다.<br>\n",
    "\n",
    "1) Notice : 공지사항 <br>\n",
    "2) Employment : 취업정보 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) 획득 데이터 csv는 다음과 같이 저장된다.\n",
    "<br>\n",
    "[공지사항]   notice.csv 파일로 저장<br><br>\n",
    "    번호,                제목,                               등록일<br>\n",
    "    1      2015-1학기 졸업능력인증 신청접수 안내         2015-06-30<br>\n",
    "    2  [LINC+] 2015학년도 1학기 경희대학교 창업동아리    2015-07-18<br>\n",
    "    3  [LINC+] Microsoft Learning Program(MLP) 교육과정  2015-07-18<br>\n",
    "    4   [중요] 전자정보대학관내 마스크 필수 착용 협조    2015-07-20<br>\n",
    "    5   [중요] 이태원 클럽 방문 내/ 외국인 검역 협조     2015-08-15<br>\n",
    "    6   2015-1학기 국제 생활관(우정원, 제2기숙사) 입사   2015-08-17<br>\n",
    "    <br>\n",
    "     .<br>\n",
    "     .<br>\n",
    "     .<br>\n",
    "<br>\n",
    "\n",
    "-공지사항 예시-<br>\n",
    "![](../image/save_notice.jpg) <br>\n",
    "<br>\n",
    "-취업정보 예시-<br>\n",
    "![](../image/save_employment.jpg) <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 공지사항 분석 <br>\n",
    "\n",
    "1) 공지사항을 분석한다. <br>\n",
    " 궁금한 공지 내용(ex. 프로그래밍)을 검색하면 그 공지가 언제를 주기로 공지되는지를 확인한다.  <br>\n",
    "\n",
    "2) 분석 내용을 가공한다. <br>\n",
    " 주기 확인 후 사용자에게 2020년을 기준으로 공지될것이라 예상되는 날짜를 제공한다.<br>\n",
    "\n",
    "1)과 2)를 각기 구현한 코드는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def analysisNo():\n",
    "    #기존 공지사항의 월 저장\n",
    "    list = []\n",
    "    #도출된 예상될 공지사항 월 저장\n",
    "    list2 = []\n",
    "    f = open('Notice.csv', 'r', -1, 'utf8')\n",
    "    i = 0\n",
    "    sch = input(\"예측할 공지사항 명을 입력하세요 : \")\n",
    "    count = 0\n",
    "    while(i<900):\n",
    "        i += 1\n",
    "        temp = f.readline()\n",
    "        if sch in temp:\n",
    "            count += 1\n",
    "            #뒤에서 부터 검색 : ,의 인덱스 반환함\n",
    "            idx = temp.rfind(',')\n",
    "            list.append(temp[idx+6:idx+8])\n",
    "\n",
    "    sum=0\n",
    "    if count == 0:\n",
    "        print(\"검색된 결과가 없습니다.\")   \n",
    "        return 0\n",
    "    else:\n",
    "        if (len(list) < 5):\n",
    "            print(\"적은 정보로 예상할 수 없습니다.\")\n",
    "        else:\n",
    "            for i in range(0, len(list)-1):\n",
    "                sum += abs(int(list[i+1]) - int(list[i]))\n",
    "            #반올림 \n",
    "            prediction = round(sum/(len(list)-1))\n",
    "            num = int(list[len(list)-1])\n",
    "            while(1):\n",
    "                num += prediction\n",
    "                if num > 17 and num <= 24:\n",
    "                    # 2019년 기준 자료를 2020년으로 바꿔줌 \n",
    "                    list2.append('2020-'+str(num-12))\n",
    "                elif num>24:\n",
    "                    break\n",
    "\n",
    "            print(\"앞으로 나올것으로 예측될 '\"+ sch + \"' 관련 공지사항은 다음과 같은 날짜로 예상됩니다.\")\n",
    "        print(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 취업정보 분석 <br>\n",
    "\n",
    "1) 취업정보를 분석한다. <br>\n",
    " 궁금한 취업 정보(ex. 삼성)를 검색하면 그 공지가 언제를 주기로 공지되는지를 확인한다.  <br>\n",
    "\n",
    "2) 분석 내용을 가공한다. <br>\n",
    " 주기 확인 후 사용자에게 2020년을 기준으로 공지될것이라 예상되는 날짜를 제공한다.<br>\n",
    "\n",
    "1)과 2)를 각기 구현한 코드는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def analysisEm():\n",
    "    #기존 취업정보의 월 저장\n",
    "    list = []\n",
    "    #도출된 예상될 공지사항 월 저장\n",
    "    list2 = []\n",
    "    f = open('Employment.csv', 'r', -1, 'utf8')\n",
    "    i = 0\n",
    "    sch = input(\"예측할 취업정보 명을 입력하세요 : \")\n",
    "    count = 0\n",
    "\n",
    "    #현재 약 300개의 취업정보이므로 적당한 400\n",
    "    while(i<400):\n",
    "        i += 1\n",
    "        temp = f.readline()\n",
    "        if sch in temp:\n",
    "            count += 1\n",
    "            #뒤에서 부터 검색 : ,의 인덱스 반환함\n",
    "            idx = temp.rfind(',')\n",
    "            list.append(temp[idx+6:idx+8])\n",
    "\n",
    "    sum=0\n",
    "    if count == 0:\n",
    "        print(\"검색된 결과가 없습니다.\")   \n",
    "        return 0\n",
    "    else:\n",
    "        if (len(list) < 5):\n",
    "            print(\"적은 정보로 예상할 수 없습니다.\")\n",
    "        else:\n",
    "            for i in range(0, len(list)-1):\n",
    "                sum += abs(int(list[i+1]) - int(list[i]))\n",
    "            #반올림 \n",
    "            prediction = round(sum/(len(list)-1))\n",
    "            num = int(list[len(list)-1])\n",
    "            while(1):\n",
    "                num += prediction\n",
    "                if num > 17 and num <= 24:\n",
    "                    # 2019년 기준 자료를 2020년으로 바꿔줌 \n",
    "                    list2.append('2020-'+str(num-12))\n",
    "                elif num>24:\n",
    "                    break\n",
    "\n",
    "            print(\"앞으로 나올것으로 예측될 '\"+ sch + \"' 관련 공지사항은 다음과 같은 날짜로 예상됩니다.\")\n",
    "        print(list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 데이터 분석 결과 및 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▲ 경희대학교 컴퓨터공학과의 공지사항 및 취업 정보 데이터를 추출하고 가공한다. 정보를 분석하여 앞으로 공지될 공지사항 및 취업 정보를 예측하고 달마다 공지되는 양을 파악한다.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "▲ 출력 예시는 다음과 같다.<br>\n",
    "<br>\n",
    "[image 파일 첨부] <br>\n",
    "![](../image/analysis_notice.jpg)\n",
    "1) 공지사항 <br>\n",
    "예측할 공지사항 명을 입력하세요 : 가을 프로그래밍<br>\n",
    "앞으로 나올것으로 예측 된 '가을 프로그래밍' 관련 공지사항은 다음과 같은 날짜로 예상됩니다.<br>\n",
    "['2020-09']<br><br>\n",
    "<br>\n",
    "![](../image/analysis_Employment.jpg)\n",
    "2) 취업 정보 <br>\n",
    "예측할 취업정보 명을 입력하세요 : 삼성<br>\n",
    "앞으로 나올것으로 예측 된 '삼성' 관련 공지사항은 다음과 같은 날짜로 예상됩니다.<br>\n",
    "['2020-06', '2020-08', '2020-10', '2020-12']<br>\n",
    "\n",
    "<br>\n",
    "기존 2015-2019년 사이에 쌓인 데이터를 기준으로 앞으로 공지될 공지날짜를 예측하여 결과값으로 나타낸다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 참고문헌 및 자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경희대학교 컴퓨터공학과 공지사항:http://ce.khu.ac.kr/index.php?hCode=BOARD&bo_idx=2 <br>\n",
    "경희대학교 컴퓨터공학과 취업정보:http://ce.khu.ac.kr/index.php?hCode=BOARD&bo_idx=3<br>\n",
    "BeautifulSoup를 활용: https://freeharmony.tistory.com/64 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 파이썬 소스코드 및 수집 데이터 (별첨)<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
